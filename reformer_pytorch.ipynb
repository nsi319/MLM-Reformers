{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "reformer_pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcc695f5951d4254ba4d0461f280c587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb561d4d751e445f82e685ada23ea9d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ebbe7cdf12a4728b94b643aac2e045c",
              "IPY_MODEL_b1f3a4687d1e4320b66293fabcf04e69"
            ]
          }
        },
        "cb561d4d751e445f82e685ada23ea9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ebbe7cdf12a4728b94b643aac2e045c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3728d4cc5a53491db060225c08e6c917",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1151,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1151,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b15f1510ad2f47acb8d39d7eeb42a4d2"
          }
        },
        "b1f3a4687d1e4320b66293fabcf04e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9e87f0784c04663a15f4eec5437bb0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.15k/1.15k [00:00&lt;00:00, 13.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00f1d36c7f3b4cf8ab171180c605f9e0"
          }
        },
        "3728d4cc5a53491db060225c08e6c917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b15f1510ad2f47acb8d39d7eeb42a4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9e87f0784c04663a15f4eec5437bb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00f1d36c7f3b4cf8ab171180c605f9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6308c6889a2947df9b27dcb281ccb935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9779979eb01401d88545a1a985ed2f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae9d74d203da4c1095af2bed445eb854",
              "IPY_MODEL_fded0333a6514d44aaa7ef112b156656"
            ]
          }
        },
        "c9779979eb01401d88545a1a985ed2f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae9d74d203da4c1095af2bed445eb854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2bc99942c14748788376030b8b355ca9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241801,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241801,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3686ee71af9141edbbb93b29ff8901b0"
          }
        },
        "fded0333a6514d44aaa7ef112b156656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03cd764f20c8445e9ca27710ac9efb6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242k/242k [00:55&lt;00:00, 4.36kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5ff1084f5b74cdba1ba8e02c19cf036"
          }
        },
        "2bc99942c14748788376030b8b355ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3686ee71af9141edbbb93b29ff8901b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03cd764f20c8445e9ca27710ac9efb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5ff1084f5b74cdba1ba8e02c19cf036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "130f7076f690486184487820fdd0108d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_178b4b00d7474af7a89d598c533e13d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f5a8e0ea6cb46eca1caadc93ea23dd9",
              "IPY_MODEL_4cf8512a0e6e4b78a9f932a9eb395b48"
            ]
          }
        },
        "178b4b00d7474af7a89d598c533e13d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f5a8e0ea6cb46eca1caadc93ea23dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56cbf2526bd64ab3b16038346fc40732",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 323306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 323306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed780aa5adba4369864b898c04f671cd"
          }
        },
        "4cf8512a0e6e4b78a9f932a9eb395b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46849a1936064c80846e5af7bb6c8cde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 323k/323k [00:41&lt;00:00, 7.81kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09cd2dd9499e44f89fa0e527830e94fd"
          }
        },
        "56cbf2526bd64ab3b16038346fc40732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed780aa5adba4369864b898c04f671cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46849a1936064c80846e5af7bb6c8cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09cd2dd9499e44f89fa0e527830e94fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsi319/Reformers/blob/main/reformer_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQ6dN_yhT6t",
        "outputId": "ab57f7dd-1d67-4c65-ad5d-c4cc1f89624f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAVW-nGThSmG",
        "outputId": "6d0cc12b-203f-49b8-df41-6bf8073b4266"
      },
      "source": [
        "!nvidia-smi\n",
        "!pip install -U reformer_pytorch\n",
        "!pip install -U transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar  5 15:53:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Collecting reformer_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/08/d6562256179e41c44c9130f1513142e2931ecd195b8d1c8ca29478b50422/reformer_pytorch-1.2.5-py3-none-any.whl\n",
            "Collecting local-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/86/f1df73868c1c433a9184d94e86cdd970951ecf14d8b556b41302febb9a12/local_attention-1.2.2-py3-none-any.whl\n",
            "Collecting axial-positional-embedding>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/27/ad886f872b15153905d957a70670efe7521a07c70d324ff224f998e52492/axial_positional_embedding-0.2.1.tar.gz\n",
            "Collecting product-key-memory\n",
            "  Downloading https://files.pythonhosted.org/packages/31/3b/c1f8977e4b04f047acc7b23c7424d1e2e624ed7031e699a2ac2287af4c1f/product_key_memory-0.1.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.7.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->reformer_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch->reformer_pytorch) (1.19.5)\n",
            "Building wheels for collected packages: axial-positional-embedding, product-key-memory\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-cp37-none-any.whl size=2905 sha256=9a9f3b9828adebd3ed70709adea5fdc426dfd4585d5cb9114c9abe4bed0e7b4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/f8/93/25b60e319a481e8f324dcb1871aff818eb0c8143ed20b732b4\n",
            "  Building wheel for product-key-memory (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for product-key-memory: filename=product_key_memory-0.1.10-cp37-none-any.whl size=3072 sha256=c36ee11bf370636c3547f950a5cda7627720c854dad2c2afa5916eb46ed0e0f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/e0/3b/fd3111a4fac652ed014ccfd4757754f006132723985e229419\n",
            "Successfully built axial-positional-embedding product-key-memory\n",
            "Installing collected packages: local-attention, axial-positional-embedding, product-key-memory, reformer-pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 local-attention-1.2.2 product-key-memory-0.1.10 reformer-pytorch-1.2.5\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 17.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.5MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=51f7045e23386c4681ee8a66706b7b44af09b3ef32c8c0f65b5496c84fe04dda\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PRejAmPYju1",
        "outputId": "76eab58c-a02e-4683-a884-ec1481501375"
      },
      "source": [
        "!wget http://www.gutenberg.org/files/2554/2554-0.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-04 06:15:29--  http://www.gutenberg.org/files/2554/2554-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1201735 (1.1M) [text/plain]\n",
            "Saving to: ‘2554-0.txt’\n",
            "\n",
            "2554-0.txt          100%[===================>]   1.15M  1.47MB/s    in 0.8s    \n",
            "\n",
            "2021-03-04 06:15:30 (1.47 MB/s) - ‘2554-0.txt’ saved [1201735/1201735]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "bcc695f5951d4254ba4d0461f280c587",
            "cb561d4d751e445f82e685ada23ea9d3",
            "7ebbe7cdf12a4728b94b643aac2e045c",
            "b1f3a4687d1e4320b66293fabcf04e69",
            "3728d4cc5a53491db060225c08e6c917",
            "b15f1510ad2f47acb8d39d7eeb42a4d2",
            "f9e87f0784c04663a15f4eec5437bb0f",
            "00f1d36c7f3b4cf8ab171180c605f9e0",
            "6308c6889a2947df9b27dcb281ccb935",
            "c9779979eb01401d88545a1a985ed2f9",
            "ae9d74d203da4c1095af2bed445eb854",
            "fded0333a6514d44aaa7ef112b156656",
            "2bc99942c14748788376030b8b355ca9",
            "3686ee71af9141edbbb93b29ff8901b0",
            "03cd764f20c8445e9ca27710ac9efb6f",
            "b5ff1084f5b74cdba1ba8e02c19cf036",
            "130f7076f690486184487820fdd0108d",
            "178b4b00d7474af7a89d598c533e13d8",
            "0f5a8e0ea6cb46eca1caadc93ea23dd9",
            "4cf8512a0e6e4b78a9f932a9eb395b48",
            "56cbf2526bd64ab3b16038346fc40732",
            "ed780aa5adba4369864b898c04f671cd",
            "46849a1936064c80846e5af7bb6c8cde",
            "09cd2dd9499e44f89fa0e527830e94fd"
          ]
        },
        "id": "asLnnhAmcsSZ",
        "outputId": "ba8eb43e-481c-4b10-eb4a-f56916d2deff"
      },
      "source": [
        "import torch\n",
        "\n",
        "from reformer_pytorch import ReformerEncDec\n",
        "from datetime import datetime\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n",
        "\n",
        "# text = \"\"\"On March 2, 2018, the Securities and Exchange Commission announced securities fraud charges against a U.K.-based broker-dealer and its investment manager in connection with manipulative trading in the securities of HD View 360 Inc., a U.S.-based microcap issuer.  The SEC also announced charges against HD View's CEO, another individual, and three entities they control for manipulating HD View's securities as well as the securities of another microcap issuer, West Coast Ventures Group Corp.  The SEC further announced the institution of an order suspending trading in the securities of HD View.These charges arise in part from an undercover operation by the Federal Bureau of Investigation, which also resulted in related criminal prosecutions against these defendants by the Office of the United States Attorney for the Eastern District of New York.In a complaint filed in the U.S. District Court for the Eastern District of New York, the SEC alleges that Beaufort Securities Ltd. and Peter Kyriacou, an investment manager at Beaufort, manipulated the market for HD View's common stock.  The scheme involved an undercover FBI agent who described his business as manipulating U.S. stocks through pump-and-dump schemes.  Kyriacou and the agent discussed depositing large blocks of microcap stock in Beaufort accounts, driving up the price of the stock through promotions, manipulating the stock's price and volume through matched trades, and then selling the shares for a large profit.The SEC's complaint against Beaufort and Kyriacou alleges that they:opened brokerage accounts for the undercover agent in the names of nominees in order to conceal his identity and his connection to the anticipated trading activity in the accounts suggested that the undercover agent could create the false appearance that HD View's stock was liquid in advance of a pump-and-dump by \"gam[ing] the market\" through matched trades executed multiple purchase orders of HD View shares with the understanding that Beaufort's client had arranged for an associate to simultaneously offer an equivalent number of shares at the same priceA second complaint filed by the SEC in the U.S. District Court for the Eastern District of New York alleges that in a series of recorded telephone conversations with the undercover agent, HD View CEO Dennis Mancino and William T. Hirschy agreed to manipulate HD View's common stock by using the agent's network of brokers to generate fraudulent retail demand for the stock in exchange for a kickback from the trading proceeds.  According to the complaint, the three men agreed that Mancino and Hirschy would manipulate HD View stock to a higher price before using the agent's brokers to liquidate their positions at an artificially inflated price.  The SEC's complaint also alleges that Mancino and Hirschy executed a \"test trade\" on Jan. 31, 2018, coordinated by the agent, consisting of a sell order placed by the defendants filled by an opposing purchase order placed by a broker into an account at Beaufort.  Unbeknownst to Mancino and Hirschy, the Beaufort account used for this trade was a nominal account that was opened and funded by the agent.  The SEC's complaint also alleges that, prior to their contact with the undercover agent, Mancino and Hirschy manipulated the market for HD View and for West Coast by using brokerage accounts that they owned, controlled, or were associated with –including TJM Investments Inc., DJK Investments 10 Inc., WT Consulting Group LLC – to effect manipulative \"matched trades.\"The SEC's complaint against Beaufort and Kyriacou charges the defendants with violating Section 10(b) of the Securities Exchange Act of 1934 and Rule 10b-5 thereunder.  The SEC also charged Hirschy, Mancino, and their corporate entities with violating Section 17(a)(1) of the Securities Act of 1933, Sections 9(a)(1), 9(a)(2), and 10(b) of the Exchange Act and Rules 10b-5(a) and (c) thereunder.  The SEC is seeking injunctions, disgorgement, prejudgment interest, penalties, and penny stock bars from Beaufort and Kyriacou.  With respect to Hirschy, Mancino, and their corporate entities, the SEC is seeking injunctions, disgorgement, prejudgment interest, penalties, penny stock bars, and an officer-and-director bar against Mancino.The investigation was conducted in the SEC's New York Regional Office by Tejal Shah and Joseph Darragh, Lorraine Collazo, and Michael D. Paley of the Microcap Fraud Task Force and supervised by Lara S. Mehraban, and in Washington, D.C. by Patrick L. Feeney, Robert Nesbitt, and Kevin Guerrero, and supervised by Antonia Chion.  Preethi Krishnamurthy and Ms. Shah will lead the SEC's litigation against Beaufort and Kyriacou.  Ann H. Petalas and Mr. Feeney, under the supervision of Cheryl Crumpton, will handle the SEC's litigation against Mancino, Hirschy, and their entities.  The SEC appreciates the assistance of the Office of the United States Attorney for the Eastern District of New York, the Federal Bureau of Investigation, the Internal Revenue Service, the Alberta Securities Commission, the Ontario Securities Commission, the Financial Conduct Authority of the United Kingdom, and the Financial Industry Regulatory Authority.The Commission's investigation in this matter is continuing.\"\"\"\n",
        "# summ = \"\"\"On March 2, 2018, the Securities and Exchange Commission charged Beaufort Securities Ltd. and Peter Kyriacou, an investment manager at Beaufort, with manipulating the market for HD View 360 Inc., a U.S.-based microcap issuer.  The SEC also announced charges against HD View's CEO, another individual, and three entities they control for manipulating HD View through pump-and-dump schemes.  According to the SEC's complaint, the defendants discussed depositing large blocks of microcap stock in Beaufort accounts, driving up the price of the stock through promotions, manipulating the stock's price and volume through matched trades, and then selling the shares for a large profit.  In a parallel action, the United States Attorney's Office for the Eastern District of New York announced criminal charges against the defendants.  On March 4, the SEC announced the entry of an order suspending trading in the securities of HD View and for West Coast, pending the outcome of a parallel criminal action by the Federal Bureau of Investigation.  Following the announcement of the suspension, HD View stock prices and volume increased significantly, and the defendants agreed to pay over $1.5 million in disgorgement, prejudgment interest, penalties, and an officer and director bar.  Beaufort agreed to settle the charges without admitting or denying the allegations of the complaint, and to pay a $1 million civil penalty. The SEC's investigation, which is continuing, has been conducted by Patrick McCluskey and Cheryl Crumpton of the SEC Enforcement Division's Market Abuse Unit in the New York Regional Office.Â  The SEC appreciates the assistance of the Financial Industry Regulatory Authority of the United Kingdom, the Canadian Securities Commission, the Alberta Securities Commission and the Ontario Securities Commission.\"\"\"\n",
        "\n",
        "text = \"\"\"He had shown signs of some obscure nervous disease before his arrest and this now developed into violent attacks of epilepsy, from which he suffered for the rest of his life. The fits occurred three or four times a year and were more frequent in periods of great strain. In 1859 he was allowed to return to Russia. He started a journal--“Vremya,” which was forbidden by the Censorship through a misunderstanding. In 1864 he lost his first wife and his brother Mihail. He was in terrible poverty, yet he took upon himself the payment of his brother’s debts. He started another journal--“The Epoch,” which within a few months was also prohibited. He was weighed down by debt, his brother’s family was dependent on him, he was forced to write at heart-breaking speed, and is said never to have corrected his work. The later years of his life were much softened by the tenderness and devotion of his second wife.\"\"\"\n",
        "summ = \"\"\"In 1864 he lost his first wife and his brother Mihail. He was in terrible poverty, yet he took upon himself the payment of his brother’s debts. He was weighed down by debt, his brother’s family was dependent on him, he was forced to write at heart-breaking speed, and is said never to have corrected his work.\"\"\" \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcc695f5951d4254ba4d0461f280c587",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1151.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6308c6889a2947df9b27dcb281ccb935",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=241801.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "130f7076f690486184487820fdd0108d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=323306.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCohdX01bhnh",
        "outputId": "d64aac2b-cc7b-44ae-c000-e21a9b9bb97f"
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=1\n",
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_QeIuzbcegN"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1WHV3qJlaIV_",
        "outputId": "ae359378-e1cb-48b2-d3b9-b94a34142e24"
      },
      "source": [
        "input_ids = tokenizer.encode(text, return_tensors='pt').long().cuda()\n",
        "output_ids = tokenizer.encode(summ, return_tensors=\"pt\").long().cuda()\n",
        "\n",
        "print(input_ids)\n",
        "print(\"Input shape: \", input_ids.shape)\n",
        "print(\"Output shape: \", output_ids.shape)\n",
        "\n",
        "t1 = datetime.now()\n",
        "print(\"Start Time: \", t1)\n",
        "DE_SEQ_LEN = 2048\n",
        "EN_SEQ_LEN = 2048\n",
        "\n",
        "enc_dec = ReformerEncDec(\n",
        "    dim = 512,\n",
        "    enc_num_tokens = 60000,\n",
        "    enc_depth = 4,\n",
        "    enc_max_seq_len = DE_SEQ_LEN,\n",
        "    dec_num_tokens = 60000,\n",
        "    dec_depth = 4,\n",
        "    dec_max_seq_len = EN_SEQ_LEN\n",
        ").cuda()\n",
        "\n",
        "t2 = datetime.now()\n",
        "print(\"Time taken to load model (in seconds): \",(t2-t1).total_seconds())\n",
        "# train_seq_in = torch.randint(0, 64000, (1, DE_SEQ_LEN)).long().cuda()\n",
        "# train_seq_out = torch.randint(0, 64000, (1, EN_SEQ_LEN)).long().cuda()\n",
        "\n",
        "train_seq_in = input_ids\n",
        "train_seq_out = output_ids\n",
        "input_mask = torch.ones(1, DE_SEQ_LEN).bool().cuda()\n",
        "\n",
        "loss = enc_dec(train_seq_in, train_seq_out, return_loss = True, enc_input_mask = input_mask)\n",
        "print(\"Loss:\",loss)\n",
        "loss.backward()\n",
        "# learn\n",
        "\n",
        "t3 = datetime.now()\n",
        "print(\"Time taken to train the model (in seconds): \",(t3-t2).total_seconds())\n",
        "# evaluate with the following\n",
        "eval_seq_in = torch.randint(0, 310, (1, DE_SEQ_LEN)).long().cuda()\n",
        "eval_seq_out_start = torch.tensor([[0.]]).long().cuda() # assume 0 is id of start token\n",
        "samples = enc_dec.generate(input_ids, eval_seq_out_start, seq_len = EN_SEQ_LEN, eos_token = 1) # assume 1 is id of stop token\n",
        "\n",
        "print(samples.shape) # (1, <= 1024) decode the tokens\n",
        "print(\"generated output: \", samples)\n",
        "summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in samples][0]\n",
        "\n",
        "\n",
        "print(\"Decoded text: \")\n",
        "print(summary)\n",
        "t4 = datetime.now()\n",
        "print(\"Time taken to generate (in seconds): \",(t4-t3).total_seconds())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[126, 100, 168,  77, 263,   7, 264, 275, 263, 266,  44, 240,  14, 280,\n",
            "         266, 274, 270,  10, 136,  16, 281, 190,  30,  24, 259,  29, 259,  49,\n",
            "         276, 144,  80,   4, 267,  10,  63,  27, 221, 254, 166,  57, 269, 262,\n",
            "         279,  19, 199, 262, 258, 281, 264, 112,  76,  78, 260, 261, 134, 266,\n",
            "          44,  64, 279, 264,  58, 279, 266, 272, 277, 188, 114, 264,  86,  23,\n",
            "         117, 276, 276, 101, 268,  88,  13,  87,  63,  44,  80,  35, 141, 259,\n",
            "         278, 140,  22,  15, 266,  14, 274, 274, 133,  10, 268,  65,  10, 259,\n",
            "         253,  22, 170,   3,  51,  42,   4,  36, 259,  52,  27, 184,  18, 144,\n",
            "          22,  10, 179,  76,  39,  40,  16, 264, 227, 266,  44,  54,  10,  50,\n",
            "          74, 267, 124, 278,  33, 263, 258,   0,  23,  59, 120,  77,  19,  26,\n",
            "          87, 260, 133, 263,  26,  98, 270, 173, 143, 278, 126,  74, 252,  19,\n",
            "           4, 258, 304, 170, 263,  94, 197, 285,   0,  10, 271, 272, 261, 135,\n",
            "         114, 264,  86,  59,  88, 280,  62, 268,  25, 242,  13, 258, 314,  25,\n",
            "         266,  38, 266, 265, 264, 279,  65, 267,   9,  66,   4,  18,  24, 270,\n",
            "          12,  16,  63, 146,  20, 278,  33, 263, 258,   0,  23,  35, 262,  63,\n",
            "          80,  22,  91,  63,   8, 141, 259,  27,  80,  17, 267, 110, 116, 258,\n",
            "         308, 264,  11, 213, 278, 126,  59,  39,   3,  16,  82, 169,  40,  73,\n",
            "          16, 260, 272, 277,  36,  67,  23, 198, 282, 154,  28,  83, 172,  13,\n",
            "          40,  71, 271,  76,  44,  80,  17, 267, 110, 116, 284, 266, 166, 280,\n",
            "         260, 266, 278, 126,  74, 252,  19,   4,  34, 237, 258, 304, 170, 263,\n",
            "          94, 197, 285, 292,   5, 258, 317, 279, 262,  86, 135, 114, 264,  86,\n",
            "          84,   6,   4,  22, 259, 273,  18,  28, 260, 265, 266,  59, 174, 266,\n",
            "         262,  40, 186, 265, 264, 280,  15,  19, 278, 126,  59,   8, 259, 264,\n",
            "         275,   5, 268,  30,  77, 263, 242, 166, 280, 260, 277,  80,  17, 267,\n",
            "         110, 116, 284, 266,  22, 128, 264,  48,  59, 166, 148,  12,  76,  60,\n",
            "          83, 277,  23,  59,  88, 274,  19,  26,   8, 267,  15, 259,  78,  23,\n",
            "         252, 289, 280,  10, 131,  20,   7, 148,  19, 277,  27, 111, 250, 232,\n",
            "          89,  26, 129,  21,  38,  10, 123,  19,  80, 230, 282, 278, 140,  35,\n",
            "          50,  16,  36, 259,  52, 266,  44,  80,  35, 141, 259, 184,  18, 270,\n",
            "          86, 127, 276, 260,  25,  19, 242,  13,   3, 259,  12,  16, 263, 142,\n",
            "          27, 166, 281, 110,  92,  44,  80,   7, 259, 274, 262,  12,   8, 141,\n",
            "         259, 278]], device='cuda:0')\n",
            "Input shape:  torch.Size([1, 436])\n",
            "Output shape:  torch.Size([1, 140])\n",
            "Start Time:  2021-03-03 14:19:49.710186\n",
            "Time taken to load model (in seconds):  1.430387\n",
            "Loss: tensor(11.3419, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
            "Time taken to train the model (in seconds):  2.390699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9163d1913546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0meval_seq_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m310\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDE_SEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0meval_seq_out_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# assume 0 is id of start token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_seq_out_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEN_SEQ_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# assume 1 is id of stop token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (1, <= 1024) decode the tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/reformer_pytorch/reformer_enc_dec.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, seq_in, seq_out_start, seq_len, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0menc_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_and_set_enc_dec_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0menc_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0menc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_out_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdec_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/reformer_pytorch/generative_tools.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, start_tokens, seq_len, eos_token, temperature, filter_logits_fn, filter_thres, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mfiltered_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_logits_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_logits\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/reformer_pytorch/autopadder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_attn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_model_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/axial_positional_embedding/axial_positional_embedding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Sequence length ({t}) must be less than the maximum sequence length allowed ({self.max_seq_len})'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Sequence length (2124) must be less than the maximum sequence length allowed (2048)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZMYdh0Y9nkg",
        "outputId": "691e2f4f-d2e3-41ca-ae9f-9e09a9c1abc4"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 30.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 23.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 21.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 22.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 16.3MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 17.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 17.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 17.0MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 17.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 17.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 17.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 17.0MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 17.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 17.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 17.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 17.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucnzjD7181SQ"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOWsctcLIae_",
        "outputId": "84b4b873-a4a7-458d-8137-84aa00fa392d"
      },
      "source": [
        "print(len(tokenizer))\n",
        "print(tokenizer.all_special_ids)\n",
        "print(tokenizer.all_special_tokens_extended)\n",
        "\n",
        "print(tokenizer.encode(\"Hello I am naren. This is a new naren. hhh\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320\n",
            "[2, 0]\n",
            "['</s>', '<unk>']\n",
            "[126, 32, 262, 33, 207, 136, 251, 263, 278, 108, 265, 24, 111, 4, 232, 273, 136, 251, 263, 278, 31, 265, 265]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uy0-d2aviiw",
        "outputId": "de704d6a-def3-4878-a93d-7771f652bc04"
      },
      "source": [
        " \n",
        "from reformer_pytorch import ReformerLM\n",
        "from reformer_pytorch.generative_tools import TrainingWrapper\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(100)\n",
        "BATCH_SIZE = 4\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATE_EVERY  = 10\n",
        "GENERATE_EVERY  = 20\n",
        "GENERATE_LENGTH = 300\n",
        "SEQ_LEN = 1024\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = ReformerLM(\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    max_seq_len = 1024,\n",
        "    num_tokens = len(tokenizer),\n",
        "    heads = 8,\n",
        "    bucket_size = 64,\n",
        "    n_hashes = 4,\n",
        "    ff_chunks = 10,\n",
        "    lsh_dropout = 0.1,\n",
        "    weight_tie = True,\n",
        "    causal = True,\n",
        "    n_local_attn_heads = 4,\n",
        "    use_full_attn = False # set this to true for comparison with full attention\n",
        ")\n",
        "\n",
        "model = TrainingWrapper(model)\n",
        "model.cuda()\n",
        "\n",
        "# prepare enwik8 data\n",
        "\n",
        "with open('/content/2554-0.txt') as file:\n",
        "    data = file.read()\n",
        "    X = tokenizer.encode(data, return_tensors=\"pt\")[0]\n",
        "    print(\"\\n\")\n",
        "    print(X)\n",
        "    print(len(X))\n",
        "    trX, vaX = np.split(X, [int(30000)])\n",
        "    data_train, data_val = trX,vaX\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        full_seq = self.data[:self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader), return_loss = True)\n",
        "        loss.backward()\n",
        "\n",
        "    print(f'\\n training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'\\nvalidation loss: {loss.item()}')\n",
        "            \n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        # prime = tokenizer.decode(inp, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "        # print(f'\\n', (prime))\n",
        "        t1 = datetime.now()\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        t2 = datetime.now()\n",
        "        print(\"\\nTime taken to generate for {} is {} seconds\".format(i,t2-t1))\n",
        "        output_str = tokenizer.decode(sample, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "\n",
        "        print(\"\\n Generated sample: \", output_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526488 > 524288). Running this sequence through the model will result in indexing errors\n",
            "training:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "tensor([140, 125, 186,  ..., 266, 278, 258])\n",
            "526488\n",
            "\n",
            " training loss: 5.9030656814575195\n",
            "\n",
            "validation loss: 5.887028217315674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 1/100 [00:12<20:10, 12.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate for 0 is 0:00:10.438608 seconds\n",
            "\n",
            " Generated sample:  veppriaskolnikovutEEilhin h h with ag didookasYou thisus(YouE in:s “ wereityad upon ag connikov wouldblequ her lookil or there Hebleyil Hexss yournikov hhinooadj h worould there looketadet<s> He wouldid or h But yourYou that there h with by youril p And yjould wor that hight The int(j is yourble y conblej conss now agadE would notid oradellght y wouldndhinYouGamehinllhileroo didad someooadhinellbleoutyould wouldnikov hidquC:YouEid isble wouldadjutousE or in Raskolnikov didss there Raskolnikov h yad somezzhinzour un_ in Butoutpp youroo thereYou oromeroourEionsx h thatble yveet And her yourhin lookilgble(id woradurnd_adoneYou “g y con conE cony nowzouldadble RaskolnikovveryEal unour heuroneri upYou( yisilet: Theould wor(icjvej your your yourilYouRadationYou would orhaetomej in worilYou or your yourhinou wornikov yxouldjysenikoviletot her: frstooalE y thereEau\n",
            "\n",
            " training loss: 5.777960777282715\n",
            "\n",
            " training loss: 5.653098106384277\n",
            "\n",
            " training loss: 5.53201961517334\n",
            "\n",
            " training loss: 5.413337707519531\n",
            "\n",
            " training loss: 5.2980780601501465\n",
            "\n",
            " training loss: 5.187178611755371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   8%|▊         | 8/100 [00:22<13:48,  9.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 5.080824851989746\n",
            "\n",
            " training loss: 4.979928016662598\n",
            "\n",
            " training loss: 4.88431978225708\n",
            "\n",
            " training loss: 4.794771194458008\n",
            "\n",
            "validation loss: 5.699926853179932\n",
            "\n",
            " training loss: 4.710766315460205\n",
            "\n",
            " training loss: 4.632154941558838\n",
            "\n",
            " training loss: 4.556112289428711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  15%|█▌        | 15/100 [00:33<09:35,  6.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 4.482320785522461\n",
            "\n",
            " training loss: 4.409242153167725\n",
            "\n",
            " training loss: 4.33792781829834\n",
            "\n",
            " training loss: 4.266335487365723\n",
            "\n",
            " training loss: 4.1945343017578125\n",
            "\n",
            " training loss: 4.121337890625\n",
            "\n",
            " training loss: 4.048537254333496\n",
            "\n",
            "validation loss: 5.669953346252441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training:  21%|██        | 21/100 [00:53<07:34,  5.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate for 20 is 0:00:10.762074 seconds\n",
            "\n",
            " Generated sample:  es a ofouskk ty wass,sksso oflad, GssEeradisg intouros of a aOppndkEsgCek ofsadostoets.s ofsgs s Eety,ndstas a of a l sb, ting a they,odss Thess TheOskslsosty as agsiet ag,gsgkystyadationionetgation,O of a andE andet p thegls of  of ast thew andyodetys ofsolss,soel conndgsadoogeou theing theets.adnds ofg a.,E theskingre intetationet  asEkornd con, of tooIkysi ands wereoEiw.ysEsgit  fromnd psE they c  thends ins ag psisings insoad a astouEy T.endad ofssk upy TO padsset insg.,s They ingin ao,ation of aing  \n",
            "\n",
            " training loss: 3.974790096282959\n",
            "\n",
            " training loss: 3.901536464691162\n",
            "\n",
            " training loss: 3.8282179832458496\n",
            "\n",
            " training loss: 3.756239891052246\n",
            "\n",
            " training loss: 3.683741331100464\n",
            "\n",
            " training loss: 3.6127848625183105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  28%|██▊       | 28/100 [01:04<05:22,  4.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 3.541712522506714\n",
            "\n",
            " training loss: 3.4701967239379883\n",
            "\n",
            " training loss: 3.3988842964172363\n",
            "\n",
            " training loss: 3.3263673782348633\n",
            "\n",
            "validation loss: 5.718576908111572\n",
            "\n",
            " training loss: 3.253476858139038\n",
            "\n",
            " training loss: 3.1813406944274902\n",
            "\n",
            " training loss: 3.107743501663208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  35%|███▌      | 35/100 [01:15<03:54,  3.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 3.0356078147888184\n",
            "\n",
            " training loss: 2.9619858264923096\n",
            "\n",
            " training loss: 2.8899595737457275\n",
            "\n",
            " training loss: 2.8181538581848145\n",
            "\n",
            " training loss: 2.7460999488830566\n",
            "\n",
            " training loss: 2.6751270294189453\n",
            "\n",
            " training loss: 2.6029303073883057\n",
            "\n",
            "validation loss: 5.7481303215026855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training:  41%|████      | 41/100 [01:35<03:27,  3.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate for 40 is 0:00:10.767253 seconds\n",
            "\n",
            " Generated sample:  ssationsky ping padations inskygs pstsg sis toys ofsovyndnds ag agsh,ingsettersingetsnd ofre ofgeslicsing pECon asky of toyodinskys ag aghinings ssationsl ofskskyss Gskyuny ceersings of to thesk,ing py it, ofs agsss of aingssking and p,orsationss sg, aations.adingssets insky CRsky Ts ag, Coetgits ofs ags, agssskysinggun  thesky,insky wass lingskyter, byndskyationskyging askysskysset toains pter,sky a p tos setetss toionsations agskyod andet theysky fromsingss weres ag, ndndskysskyssssadyssationsndsings of theun,ss fromyody\n",
            "\n",
            " training loss: 2.531613826751709\n",
            "\n",
            " training loss: 2.459500312805176\n",
            "\n",
            " training loss: 2.389819622039795\n",
            "\n",
            " training loss: 2.318971633911133\n",
            "\n",
            " training loss: 2.2498104572296143\n",
            "\n",
            " training loss: 2.180122137069702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  48%|████▊     | 48/100 [01:45<02:31,  2.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 2.110739231109619\n",
            "\n",
            " training loss: 2.041620969772339\n",
            "\n",
            " training loss: 1.9733121395111084\n",
            "\n",
            " training loss: 1.9071053266525269\n",
            "\n",
            "validation loss: 5.793095111846924\n",
            "\n",
            " training loss: 1.8394664525985718\n",
            "\n",
            " training loss: 1.7730393409729004\n",
            "\n",
            " training loss: 1.7088572978973389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  55%|█████▌    | 55/100 [01:56<01:52,  2.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 1.6436196565628052\n",
            "\n",
            " training loss: 1.5806186199188232\n",
            "\n",
            " training loss: 1.518416166305542\n",
            "\n",
            " training loss: 1.4580013751983643\n",
            "\n",
            " training loss: 1.3976619243621826\n",
            "\n",
            " training loss: 1.338612675666809\n",
            "\n",
            " training loss: 1.2803356647491455\n",
            "\n",
            "validation loss: 5.865043640136719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training:  61%|██████    | 61/100 [02:16<01:47,  2.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate for 60 is 0:00:10.726659 seconds\n",
            "\n",
            " Generated sample:  geingsskyodinins aboutressE postors ofs agsatsy to ps of asain Gters,ndersings agsingsations ags,unationskyod and Pun conGuts about,y wassl of a lunations of a llyyationsation,gunssy to B,s ofsorskingy wasets ags;hendsing ofs againain p tooding pryodationss ofunationsky, nds of up Byineringskyodskyetsingunhed ups agations and Proingndsings to, pyin, of a lingsgunationskyod upnds pssss,sgol toodndsatingskyets ofsk,sky, up,s. Ts tos pterndsskyge sh,y fromterter, ofsky,skyation, “inss ofskyndsster fromungeunsunationnds psationsolyodations of aysky fromlyationsovy,nds ags ag\n",
            "\n",
            " training loss: 1.2243216037750244\n",
            "\n",
            " training loss: 1.1696617603302002\n",
            "\n",
            " training loss: 1.1155266761779785\n",
            "\n",
            " training loss: 1.0630531311035156\n",
            "\n",
            " training loss: 1.011847734451294\n",
            "\n",
            " training loss: 0.9626076221466064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  68%|██████▊   | 68/100 [02:27<01:16,  2.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 0.9151358604431152\n",
            "\n",
            " training loss: 0.8677418231964111\n",
            "\n",
            " training loss: 0.8209632039070129\n",
            "\n",
            " training loss: 0.7788736820220947\n",
            "\n",
            "validation loss: 5.956666469573975\n",
            "\n",
            " training loss: 0.7358688116073608\n",
            "\n",
            " training loss: 0.6941136121749878\n",
            "\n",
            " training loss: 0.6553387641906738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  75%|███████▌  | 75/100 [02:38<00:53,  2.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 0.6177589893341064\n",
            "\n",
            " training loss: 0.5809740424156189\n",
            "\n",
            " training loss: 0.5456949472427368\n",
            "\n",
            " training loss: 0.5120375752449036\n",
            "\n",
            " training loss: 0.4804397523403168\n",
            "\n",
            " training loss: 0.4504939615726471\n",
            "\n",
            " training loss: 0.4213239848613739\n",
            "\n",
            "validation loss: 6.057682514190674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training:  81%|████████  | 81/100 [02:57<00:47,  2.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate for 80 is 0:00:10.624609 seconds\n",
            "\n",
            " Generated sample:  Bunndsationlyationndndssk,un Bndgegeins agtery Gutensgeing andndations;ly.sationsndsationsGGsunndernders agationsations ags,ations.s of the cndge shndetgendatndsationster con, of knowsated:ssationsation, givessationsatOsnders, agndsky,ys againGndersationsndGnders of pndergsationsations againyodreAEnd ags ofatly tnderskyskynders of the f tondssyodingsheationsationsationsationsations of agendG asing prendssations,ndursationskyodsationskingssationsationsationsuncesingndsationsationslyly and susations ofyoding of the tationsnd,ndsationsations, bys ag,sations agsationOsk, of as of  But,s whats agter, gndndsky Garndsations\n",
            "\n",
            " training loss: 0.3930705487728119\n",
            "\n",
            " training loss: 0.36621561646461487\n",
            "\n",
            " training loss: 0.34167540073394775\n",
            "\n",
            " training loss: 0.3173447847366333\n",
            "\n",
            " training loss: 0.2948683798313141\n",
            "\n",
            " training loss: 0.27383843064308167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  88%|████████▊ | 88/100 [03:08<00:26,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 0.25379714369773865\n",
            "\n",
            " training loss: 0.23526564240455627\n",
            "\n",
            " training loss: 0.21676293015480042\n",
            "\n",
            " training loss: 0.19972017407417297\n",
            "\n",
            "validation loss: 6.174382209777832\n",
            "\n",
            " training loss: 0.18375617265701294\n",
            "\n",
            " training loss: 0.16971945762634277\n",
            "\n",
            " training loss: 0.15591777861118317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:  95%|█████████▌| 95/100 [03:19<00:10,  2.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 0.14277097582817078\n",
            "\n",
            " training loss: 0.13101473450660706\n",
            "\n",
            " training loss: 0.11997829377651215\n",
            "\n",
            " training loss: 0.10992483049631119\n",
            "\n",
            " training loss: 0.10051631182432175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining: 100%|██████████| 100/100 [03:26<00:00,  2.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " training loss: 0.09182821959257126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBLPLgkF6lHO",
        "outputId": "b3c99700-9b37-43ec-8fe3-ef7fcbae9d0b"
      },
      "source": [
        "text = \"A few months later\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").cuda()\n",
        "t1 = datetime.now()\n",
        "output_ids = model.generate(input_ids,100)\n",
        "t2 = datetime.now()\n",
        "print(\"\\nTime taken to generate is {} seconds\".format(t2-t1))\n",
        "print(output_ids)\n",
        "output_str = tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "print(\"Generated sample: \", output_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate is 0:00:03.495704 seconds\n",
            "tensor([[275, 258, 317, 300, 158,  44,  13, 258, 314,  67, 109, 188, 187, 272,\n",
            "         259,  58, 277, 242, 258, 313, 272,  98, 272, 227,  38, 216, 262,  63,\n",
            "         262, 108,  51, 259,  76,  38, 272, 108, 265,  24, 265,  24, 265,  24,\n",
            "         265, 271,  26,  13, 125, 186, 272, 276, 264, 134,  48, 311,  27,  84,\n",
            "         271, 262,  63,  27,  84, 174,   9,  41, 260, 265,  87,  63,  82, 123,\n",
            "          92, 266, 178, 266, 262, 259,  89,  27, 166, 193,  53,  21, 265,   9,\n",
            "          66, 186,  56, 277,  54,   3, 259, 271, 266,  44, 253,  87, 289, 270,\n",
            "          70,  56]], device='cuda:0')\n",
            "Generated sample:  g EBook of the Cetter from Byele, by Fy Ryodor Dosto Timeentory Thishishishm to the ProyficklyK and withmost and with alou youth restrictions whatsoever and de ex no choughro it, g tems of or re-use it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsxYWCBX8hJ8",
        "outputId": "4ae445f8-921d-44da-d4f1-e59197a25e4b"
      },
      "source": [
        "google = AutoModelWithLMHead.from_pretrained(\"google/reformer-crime-and-punishment\")\n",
        "google_tokenizer = AutoTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\n",
        "print(google_tokenizer.decode(google.generate(google_tokenizer.encode(\"A few months later\", return_tensors=\"pt\"), do_sample=True,temperature=0.7, max_length=100)[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:970: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "Some weights of ReformerModelWithLMHead were not initialized from the model checkpoint at google/reformer-crime-and-punishment and are newly initialized: ['reformer.encoder.layers.0.attention.self_attention.mask_value_float16', 'reformer.encoder.layers.0.attention.self_attention.mask_value_float32', 'reformer.encoder.layers.1.attention.self_attention.self_mask_value_float16', 'reformer.encoder.layers.1.attention.self_attention.self_mask_value_float32', 'reformer.encoder.layers.1.attention.self_attention.mask_value_float16', 'reformer.encoder.layers.1.attention.self_attention.mask_value_float32', 'reformer.encoder.layers.2.attention.self_attention.mask_value_float16', 'reformer.encoder.layers.2.attention.self_attention.mask_value_float32', 'reformer.encoder.layers.3.attention.self_attention.self_mask_value_float16', 'reformer.encoder.layers.3.attention.self_attention.self_mask_value_float32', 'reformer.encoder.layers.3.attention.self_attention.mask_value_float16', 'reformer.encoder.layers.3.attention.self_attention.mask_value_float32', 'reformer.encoder.layers.4.attention.self_attention.mask_value_float16', 'reformer.encoder.layers.4.attention.self_attention.mask_value_float32', 'reformer.encoder.layers.5.attention.self_attention.self_mask_value_float16', 'reformer.encoder.layers.5.attention.self_attention.self_mask_value_float32', 'reformer.encoder.layers.5.attention.self_attention.mask_value_float16', 'reformer.encoder.layers.5.attention.self_attention.mask_value_float32']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py:898: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  relevant_bucket_idx = (bucket_idx == (bucket_idx.shape[-1] - 1)).nonzero()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few months later, but she was only the old woman, but her little. “Here!” she cried, laughing, trying to figure, drawinging her head head. He laid time he turned to the other. Marmeladov was in the new had not\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipyToi6O9D6Z",
        "outputId": "76b6a41f-55d7-4bcd-cbea-bf5f8089f720"
      },
      "source": [
        "text = \"A few months later\"\n",
        "input_ids = google_tokenizer.encode(text, return_tensors=\"pt\").cuda()\n",
        "t1 = datetime.now()\n",
        "output_ids = model.generate(input_ids,100)\n",
        "t2 = datetime.now()\n",
        "print(\"\\nTime taken to generate is {} seconds\".format(t2-t1))\n",
        "print(output_ids)\n",
        "output_str = google_tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "print(\"Generated sample: \", output_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken to generate is 0:00:03.428068 seconds\n",
            "tensor([[28515, 30590,   173, 43251,  5375,  3872,  1268,     8,  6203,    24,\n",
            "             6,    49,   367, 13617, 50118,   133, 42735, 50118,     5,   274,\n",
            "           219, 28145,   211,  2603,   139,  3623, 18708, 50118,  3623, 18708,\n",
            "         50118,   163,   756,  2226, 23985,   492,   117,    42,  8793,     6,\n",
            "           492,    24, 21979,   370,    24,  3037,    38,    21,  1166,    27,\n",
            "           870, 13593,  3486,    78,   220, 22401,  2124,     5, 50118, 23375,\n",
            "             5, 50118,  4283,   523,    30,   219, 28145,  6372,    51,   779,\n",
            "          6372,  1519,  3503, 27614, 29183,     6, 24751,   534,    35,    58,\n",
            "         12613,   336, 50118,   250,     9,     5, 45326,  3885,     6,     5,\n",
            "         50118, 50118,   849, 50140, 50118, 50118, 42779,  1957, 13735, 50118]],\n",
            "       device='cuda:0')\n",
            "Generated sample:  ss wisin beurhecusive?”na suesinisisor c and at theyhehe dusimin lle saidouheinhe\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}